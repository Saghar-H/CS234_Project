{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1294d6c70>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma = 0.5\n",
    "device = torch.device(\"cpu\")\n",
    "lr = 1e-2\n",
    "seed = 1365\n",
    "num_iterations = 500\n",
    "np.random.seed(1365)\n",
    "torch.manual_seed(1365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TDLambda(torch.nn.Module):\n",
    "    def __init__(self, num_states, num_features, gamma=1.0):\n",
    "        super(TDLambda, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.num_states = num_states\n",
    "        self.num_features = num_features\n",
    "        self.lmbda = torch.nn.Parameter(torch.tensor(0, requires_grad = True, dtype = torch.float32))\n",
    "        self.theta = torch.nn.Parameter(torch.randn((num_features), requires_grad = True, dtype = torch.float32))\n",
    "        self.features = torch.randn((num_states, num_features), requires_grad = False, dtype = torch.float32)\n",
    "    '''\n",
    "    Runs TD for one episode, calculates the lambda return and value function of the first states\n",
    "    '''\n",
    "    def forward(self, episode):\n",
    "        lambda_g = episode[-1][2]\n",
    "        #pdb.set_trace()\n",
    "        for t in range(len(episode)-2,-1,-1):\n",
    "            cur_state, action, reward, next_state = episode[t]\n",
    "            lambda_g = reward + self.gamma * (1-self.lmbda) * torch.dot(self.features[next_state], self.theta) \\\n",
    "                        + self.gamma * self.lmbda * lambda_g\n",
    "        \n",
    "        #BUGBUG: Currently it only returns the values at the first state of the trajectory\n",
    "        return lambda_g, torch.dot(self.features[cur_state],self.theta)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = np.array([[(1,0,0,2), (2,0,0,3), (3,1,0,2), (2,2,1,4)],\n",
    "                  [(1,1,0,3), (3,2,0,2), (2,1,0,3), (3,0,1,4)],\n",
    "                  [(1,3,0,3), (3,2,0,2), (2,1,0,1), (1,3,1,4)],\n",
    "                  [(1,1,0,0), (0,3,0,2), (2,3,0,3), (3,1,1,4)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor(0., requires_grad=True), Parameter containing:\n",
      "tensor([-0.0773,  0.4260, -1.5394], requires_grad=True)]\n",
      "0 20.156326293945312\n",
      "10 0.19459861516952515\n",
      "20 0.13731077313423157\n",
      "30 0.09719155728816986\n",
      "40 0.06862808018922806\n",
      "50 0.04816114529967308\n",
      "60 0.03350945562124252\n",
      "70 0.023084532469511032\n",
      "80 0.015737013891339302\n",
      "90 0.010617044754326344\n",
      "100 0.007092426531016827\n",
      "110 0.004695149138569832\n",
      "120 0.003083100076764822\n",
      "130 0.002010277472436428\n",
      "140 0.00130283716134727\n",
      "150 0.0008400421356782317\n",
      "160 0.000539321918040514\n",
      "170 0.0003450352814979851\n",
      "180 0.00022010043903719634\n",
      "190 0.00014007087156642228\n",
      "200 8.896979852579534e-05\n",
      "210 5.64242982363794e-05\n",
      "220 3.573983849491924e-05\n",
      "230 2.261507870571222e-05\n",
      "240 1.429862004442839e-05\n",
      "250 9.034723007061984e-06\n",
      "260 5.706288447981933e-06\n",
      "270 3.602413244152558e-06\n",
      "280 2.2732133402314503e-06\n",
      "290 1.434385012544226e-06\n",
      "300 9.048360425367719e-07\n",
      "310 5.70813085687405e-07\n",
      "320 3.5986346347272047e-07\n",
      "330 2.269528778242602e-07\n",
      "340 1.4315018859178963e-07\n",
      "350 9.019466773452223e-08\n",
      "360 5.688555759775227e-08\n",
      "370 3.5830886702115095e-08\n",
      "380 2.2583673597864617e-08\n",
      "390 1.4237301115826995e-08\n",
      "400 8.980297394600711e-09\n",
      "410 5.6549644966708e-09\n",
      "420 3.561066108659361e-09\n",
      "430 2.246839159170122e-09\n",
      "440 1.4200907116901362e-09\n",
      "450 8.940048701333581e-10\n",
      "460 5.641673794798407e-10\n",
      "470 3.58816976131493e-10\n",
      "480 2.2506085883833293e-10\n",
      "490 1.4298606743068376e-10\n"
     ]
    }
   ],
   "source": [
    "model = TDLambda(5,3)\n",
    "print(list(model.parameters()))\n",
    "#pdb.set_trace()\n",
    "criterion = torch.nn.MSELoss(reduction='sum')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "for t in range(num_iterations):\n",
    "    # Forward pass: Compute predicted y by passing x to the model\n",
    "    loss = 0\n",
    "    for trace in traces:\n",
    "        g_return, v_estimate = model(trace)\n",
    "        # Compute and print loss\n",
    "        loss += criterion(g_return, v_estimate)\n",
    "    if t % 10 == 0:\n",
    "        print(t, loss.item())\n",
    "\n",
    "    # Zero gradients, perform a backward pass, and update the weights.\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4, 4)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
